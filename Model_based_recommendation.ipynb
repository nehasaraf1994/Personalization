{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "import math\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset : Amazon Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_movies = pd.read_csv(\"ratings_Movies_and_TV.csv\")#read data in csv format to dataframe\n",
    "amazon_movies.columns = [\"User_Id\", \"Item_Id\", \"Rating\", \"TimeStamp\"]#set column names in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking train parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r item_count\n",
    "%store -r user_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of most frequently rated items\n",
    "average_rating = pd.DataFrame(amazon_movies.groupby('Item_Id')['Rating'].mean())\n",
    "average_rating['ratingCount'] = pd.DataFrame(amazon_movies.groupby('Item_Id')['Rating'].count())\n",
    "average_rating = average_rating.sort_values('ratingCount', ascending=False)\n",
    "average_rating = average_rating.reset_index()\n",
    "frequent_rated_items = average_rating[:item_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the data to include only most frequently rated items\n",
    "amazon_movies_item_subset = amazon_movies[(amazon_movies['Item_Id'].isin(frequent_rated_items.Item_Id)).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of users that most frequently rate items\n",
    "user_rated_most = pd.DataFrame(amazon_movies_item_subset.groupby('User_Id')['Item_Id'].count())\n",
    "user_rated_most = user_rated_most.sort_values('Item_Id', ascending=False)\n",
    "user_rated_most = user_rated_most.reset_index()\n",
    "user_rated_most.columns = [\"User_Id\", \"rated_items\"]\n",
    "top_user_rated_most = user_rated_most[:user_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the data to include only users that most frequently rate items\n",
    "amazon_movies_user_subset = amazon_movies_item_subset[(amazon_movies_item_subset['User_Id'].isin(top_user_rated_most.User_Id)).tolist()]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do random sampling of subset of data to create a test set\n",
    "import random\n",
    "# Parameter: dataset is the train set from which we take test dataset\n",
    "# Parameter: k is the number of users-item combination for which we want to predict ratings\n",
    "def create_testdataset(dataset,k):\n",
    "    test_df = pd.DataFrame(columns=[\"User_Id\",\"Item_Id\",\"Rating\"])\n",
    "    for i in range(0,k):\n",
    "        index = random.choice(dataset.index.values.tolist())\n",
    "        user = dataset.loc[index,'User_Id']\n",
    "        item = dataset.loc[index,'Item_Id']\n",
    "        rating = dataset.loc[index,'Rating']\n",
    "        df = pd.DataFrame([[user,item,rating]],columns=[\"User_Id\",\"Item_Id\",\"Rating\"])\n",
    "        test_df = test_df.append(df)\n",
    "        \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking test parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r test_rows\n",
    "test_df = create_testdataset(amazon_movies_user_subset,test_rows)\n",
    "test_df = test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print no. of unique users and items in train set\n",
    "print(\"Unique Items:\",amazon_movies_user_subset.Item_Id.unique().shape[0])\n",
    "print(\"Unique Users:\",amazon_movies_user_subset.User_Id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sparsity of user_item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create user-item matrix from train set dataframe\n",
    "user_item_pivot = amazon_movies_item_subset.pivot(index=\"User_Id\",columns=\"Item_Id\", values=\"Rating\")\n",
    "userId = amazon_movies_item_subset.index\n",
    "itemId = amazon_movies_item_subset.columns\n",
    "user_item_matrix = csr_matrix(user_item_pivot.values)\n",
    "user_item_pivot_filled_zeros = user_item_pivot.fillna(0)\n",
    "user_item_matrix_filled_zeros = csr_matrix(user_item_pivot_filled_zeros.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the ratings of rows in test set from train set\n",
    "test_df = test_df.reset_index()\n",
    "for i in range(0,test_df.shape[0]):\n",
    "    user_item_pivot.loc[test_df.User_Id[i]][test_df.Item_Id[i]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate sparsity of user_item matrix\n",
    "missing = pd.DataFrame(np.isnan(user_item_pivot).sum()/np.prod(user_item_pivot.shape))\n",
    "missing = missing.reset_index()\n",
    "missing.columns = [\"Item_Id\", \"percent_missing\"]\n",
    "print(\"Sparsity Percentage:\",(missing.percent_missing.sum())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of ratings for each user\n",
    "user_item_pivot['Mean'] = user_item_pivot.mean(axis=1)\n",
    "#store in another matrix and subract mean column from all other columns in user-item matrix\n",
    "user_item_pivot2 = user_item_pivot\n",
    "user_item_pivot2 = user_item_pivot2.sub(user_item_pivot['Mean'].reset_index().Mean.tolist(),axis=0)\n",
    "user_item_pivot2['Mean'] = user_item_pivot['Mean']\n",
    "user_item_pivot2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_demeaned = user_item_pivot2.fillna(0).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use matrix factorization to convert user-item matrix to new latent space\n",
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(user_item_demeaned, k = 25)\n",
    "sigma = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate predicted ratings using reduced latent space matrices\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + np.array(user_item_pivot['Mean'].reset_index().Mean.tolist()).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create user-item matrix of predictions\n",
    "user_item_predictions_model = pd.DataFrame(all_user_predicted_ratings, columns = user_item_demeaned.columns)\n",
    "user_item_predictions_model.index = user_item_demeaned.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_predictions_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints predicted and orginal ratings given test set and array of predicted ratings for user-item combinations in test set\n",
    "def print_ratings(test_df,user_item_predicted):\n",
    "    user_item_predicted_array = []\n",
    "    for i in range(0,test_df.shape[0]):\n",
    "        print(\"User ID:\", test_df.User_Id[i])\n",
    "        print(\"Predicted Ratings:\", user_item_predicted.loc[test_df.User_Id[i]][test_df.Item_Id[i]])\n",
    "        print(\"Original Ratings:\",test_df.Rating[i])\n",
    "        print(\"\\n\")\n",
    "        user_item_predicted_array.append(user_item_predicted.loc[test_df.User_Id[i]][test_df.Item_Id[i]])\n",
    "    \n",
    "    return np.array(user_item_predicted_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns rmse given predicted and observed rating arrays\n",
    "def calculate_rmse(predicted_rating,observed_rating):\n",
    "    rmse = np.sqrt((np.sum(np.square(predicted_rating-observed_rating)))/(len(observed_rating)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns mae given predicted and observed rating arrays\n",
    "def calculate_mae(predicted_rating,observed_rating):\n",
    "    mae = (np.sum(abs(predicted_rating-observed_rating)))/(len(observed_rating))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observed and Predicted Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print observed and predicted ratings, rmse and mae\n",
    "user_item_predicted_array = print_ratings(test_df,user_item_predictions_model)\n",
    "test_ratings_array = np.array(test_df.Rating)\n",
    "rmse = calculate_rmse(user_item_predicted_array,test_ratings_array)\n",
    "print(\"Root Mean Square Error for Test Data:\", rmse)\n",
    "mae = calculate_mae(user_item_predicted_array,test_ratings_array)\n",
    "print(\"Mean Absolute Error for Test Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns item coverage for dataset ie. percentage of items predicted from all items.\n",
    "def calculate_item_coverage(k,user_item_predicted):\n",
    "    items_recommended =[]\n",
    "    for i in range(0,user_item_predicted.shape[0]):\n",
    "        top_k_items=[]\n",
    "        target_user = user_item_predicted.index[i]\n",
    "        top_k_items=top_k_items_recommended(k,target_user,user_item_predicted)\n",
    "        items_recommended.extend(top_k_items)\n",
    "        \n",
    "    items_recommended = np.unique(np.array(items_recommended)).tolist()\n",
    "    items_coverage = len(items_recommended)/user_item_predicted.shape[1]\n",
    "    return items_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns top-k recommened items for any user\n",
    "def top_k_items_recommended(k,userid,user_item_predicted):\n",
    "    items_target = user_item_predicted.loc[userid].reset_index()\n",
    "    top_k_items = items_target.sort_values(userid, ascending=False)[:k].Item_Id.tolist()\n",
    "    return top_k_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catalog Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns catalog coverage for dataset ie. percentage of user-item pairs predicted from all possible user-item pairs\n",
    "def calculate_catalog_coverage(k,user_item_predicted):\n",
    "    total_user_item_pairs = user_item_predicted.shape[0]*user_item_predicted.shape[1]\n",
    "    #since recommending items to all the users\n",
    "    total_user_items_recommended = user_item_predicted.shape[0]*k\n",
    "    coverage_ratio = total_user_items_recommended/total_user_item_pairs\n",
    "    return coverage_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Item Coverage:\",calculate_item_coverage(5,user_item_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Catalog Coverage:\",calculate_catalog_coverage(5,user_item_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The time taken to run with these parameters:\", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
