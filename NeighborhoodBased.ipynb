{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "import math\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset : Amazon Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_movies = pd.read_csv(\"ratings_Movies_and_TV.csv\")#read data in csv format to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_movies.columns = [\"User_Id\", \"Item_Id\", \"Rating\", \"TimeStamp\"]#set column names in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency plot for different types of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\",size=15)#Plot count for each rating\n",
    "amazon_movies.Rating.value_counts(sort=True).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking train parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r item_count\n",
    "%store -r user_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of most frequently rated items\n",
    "average_rating = pd.DataFrame(amazon_movies.groupby('Item_Id')['Rating'].mean())\n",
    "average_rating['ratingCount'] = pd.DataFrame(amazon_movies.groupby('Item_Id')['Rating'].count())\n",
    "average_rating = average_rating.sort_values('ratingCount', ascending=False)\n",
    "average_rating = average_rating.reset_index()\n",
    "frequent_rated_items = average_rating[:item_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the data to include only most frequently rated items\n",
    "amazon_movies_item_subset = amazon_movies[(amazon_movies['Item_Id'].isin(frequent_rated_items.Item_Id)).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of users that most frequently rate items\n",
    "user_rated_most = pd.DataFrame(amazon_movies_item_subset.groupby('User_Id')['Item_Id'].count())\n",
    "user_rated_most = user_rated_most.sort_values('Item_Id', ascending=False)\n",
    "user_rated_most = user_rated_most.reset_index()\n",
    "user_rated_most.columns = [\"User_Id\", \"rated_items\"]\n",
    "top_user_rated_most = user_rated_most[:user_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset the data to include only users that most frequently rate items\n",
    "amazon_movies_user_subset = amazon_movies_item_subset[(amazon_movies_item_subset['User_Id'].isin(top_user_rated_most.User_Id)).tolist()]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataset Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do random sampling of subset of data to create a test set\n",
    "import random\n",
    "# Parameter: dataset is the train set from which we take test dataset\n",
    "# Parameter: k is the number of users-item combination for which we want to predict ratings\n",
    "def create_testdataset(dataset,k):\n",
    "    ho\n",
    "    for i in range(0,k):\n",
    "        index = random.choice(dataset.index.values.tolist())\n",
    "        user = dataset.loc[index,'User_Id']\n",
    "        item = dataset.loc[index,'Item_Id']\n",
    "        rating = dataset.loc[index,'Rating']\n",
    "        df = pd.DataFrame([[user,item,rating]],columns=[\"User_Id\",\"Item_Id\",\"Rating\"])\n",
    "        test_df = test_df.append(df)\n",
    "    return test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking test parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r test_rows\n",
    "test_df = create_testdataset(amazon_movies_user_subset,test_rows)\n",
    "test_df = test_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print no. of unique users and items in train set\n",
    "print(\"Unique Items:\",amazon_movies_user_subset.Item_Id.unique().shape[0])\n",
    "print(\"Unique Users:\",amazon_movies_user_subset.User_Id.unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sparsity of user_item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create user-item matrix from train set dataframe\n",
    "user_item_pivot = amazon_movies_user_subset.pivot(index=\"User_Id\",columns=\"Item_Id\", values=\"Rating\")\n",
    "userId = user_item_pivot.index\n",
    "itemId = user_item_pivot.columns\n",
    "user_item_matrix = csr_matrix(user_item_pivot.values)\n",
    "user_item_pivot_filled_zeros = user_item_pivot.fillna(0)\n",
    "user_item_matrix_filled_zeros = csr_matrix(user_item_pivot_filled_zeros.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the ratings of rows in test set from train set\n",
    "for i in range(0,test_df.shape[0]):\n",
    "    user_item_pivot.loc[test_df.User_Id[i]][test_df.Item_Id[i]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate sparsity of user_item matrix\n",
    "missing = pd.DataFrame(np.isnan(user_item_pivot).sum()/np.prod(user_item_pivot.shape))\n",
    "missing = missing.reset_index()\n",
    "missing.columns = [\"Item_Id\", \"percent_missing\"]\n",
    "print(\"Sparsity Percentage:\",(missing.percent_missing.sum())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Birch Clustering to create peer group for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation and hyper-parameter tuning to find optimal number of clusters and branching factor\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "RAND_STATE=50  # for reproducibility and consistency\n",
    "folds=3\n",
    "k_fold = KFold(n_splits=folds, shuffle=True, random_state=RAND_STATE)\n",
    "hyperparams = {\n",
    "    \"branching_factor\": [20,50,70,100],\n",
    "    \"n_clusters\": [5,10,50,70,100,200],\n",
    "}\n",
    "\n",
    "bir = Birch()  # sets jobs equal to number of cores\n",
    "\n",
    "def silhouette_score(estimator, X):\n",
    "    clusters = estimator.fit_predict(X)\n",
    "    score = metrics.silhouette_score(X, clusters)\n",
    "    return score\n",
    "\n",
    "ensemble = GridSearchCV(\n",
    "    estimator=bir,\n",
    "    param_grid=hyperparams,\n",
    "    scoring=silhouette_score,\n",
    "    cv=k_fold\n",
    ")\n",
    "ensemble.fit(user_item_matrix_filled_zeros)\n",
    "print(ensemble.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise and fit birch clustering model to dataset\n",
    "import numpy as np\n",
    "from sklearn.cluster import Birch\n",
    "estimator = Birch(branching_factor= ensemble.best_params_[\"branching_factor\"],n_clusters=ensemble.best_params_[\"n_clusters\"])\n",
    "estimator.fit(user_item_matrix_filled_zeros)\n",
    "estimator.labels_\n",
    "neighbors = {i: np.where(estimator.labels_ == i)[0] for i in range(estimator.n_clusters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns k nearest neighbors given a user id\n",
    "def get_neighbors2(query_index,user_item_matrix_filled_zeros):\n",
    "    for cluster in neighbors:\n",
    "        cluster = neighbors[cluster].tolist()\n",
    "        print()\n",
    "        if query_index in cluster:\n",
    "            return [user_item_matrix_filled_zeros.index[x] for x in cluster if x != query_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize user-item Matrix: Subtracting the Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate mean of ratings for each user\n",
    "user_item_pivot['Mean'] = user_item_pivot.mean(axis=1)\n",
    "user_item_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store in another matrix and subract mean column from all other columns in user-item matrix\n",
    "user_item_pivot2=user_item_pivot\n",
    "user_item_pivot2 = user_item_pivot2.sub(user_item_pivot['Mean'].reset_index().Mean.tolist(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_pivot2['Mean'] = user_item_pivot['Mean']\n",
    "user_item_pivot2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calulate similarity matrix using Pearson Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user-user similarity matrix\n",
    "user_item_normalized = user_item_pivot2.fillna(0).iloc[:,:-1]\n",
    "pearson_similarity = user_item_normalized.dot(user_item_normalized.T)\n",
    "sim_denom_sqrt = np.sqrt(np.sum(np.square(user_item_normalized), axis=1))\n",
    "sim_denom_sqrt = np.array(sim_denom_sqrt)[np.newaxis]\n",
    "similarity_denom = sim_denom_sqrt.T.dot(sim_denom_sqrt)\n",
    "pearson_similarity = (pearson_similarity/similarity_denom).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the predicted user-item matrix : Neighborhood-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user_item predicted values matrix\n",
    "user_item_df = pd.DataFrame(columns=[\"User_Id\",\"Item_Id\",\"Rating\"])\n",
    "user_item_df['User_Id'] = amazon_movies_user_subset['User_Id']\n",
    "user_item_df['Item_Id'] = amazon_movies_user_subset['Item_Id']\n",
    "user_item_df['Rating'] = [0]*amazon_movies_user_subset.shape[0]\n",
    "user_item_predicted = user_item_df.pivot(index=\"User_Id\",columns=\"Item_Id\", values=\"Rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict ratings that are missing in user-item matrix using ratings of users in peer set and similarity matrix\n",
    "for i in range(0,user_item_pivot2.shape[0]):\n",
    "    target_user = user_item_pivot2.index[i]\n",
    "    items_target = user_item_pivot2.loc[target_user]\n",
    "    mean_target_user=items_target['Mean']\n",
    "    items_target = items_target.reset_index()\n",
    "    items_target_negative = items_target[items_target[target_user].isna()]\n",
    "    nearest_neighbor = get_neighbors2(i,user_item_pivot2)\n",
    "  \n",
    "\n",
    "    \n",
    "    for j in items_target_negative['Item_Id']:\n",
    "        sum_rating_nn = 0\n",
    "        similarity_nn = 0\n",
    "        for k in nearest_neighbor:\n",
    "            if not (math.isnan(user_item_pivot2.loc[k][j])):\n",
    "                sum_rating_nn=sum_rating_nn+((pearson_similarity.loc[target_user][k])*(user_item_pivot2.loc[k][j]))\n",
    "                similarity_nn = similarity_nn + abs(pearson_similarity.loc[target_user][k])\n",
    "                \n",
    "        if(similarity_nn!=0):\n",
    "            user_item_predicted.loc[target_user][j] = mean_target_user + (sum_rating_nn/similarity_nn)\n",
    "        else:\n",
    "            user_item_predicted.loc[target_user][j] = mean_target_user\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints predicted and orginal ratings given test set and array of predicted ratings for user-item combinations in test set\n",
    "def print_ratings(test_df,user_item_predicted):\n",
    "    user_item_predicted_array = []\n",
    "    for i in range(0,test_df.shape[0]):\n",
    "        print(\"User ID:\", test_df.User_Id[i])\n",
    "        print(\"Predicted Ratings:\", user_item_predicted.loc[test_df.User_Id[i]][test_df.Item_Id[i]])\n",
    "        print(\"Original Ratings:\",test_df.Rating[i])\n",
    "        print(\"\\n\")\n",
    "        user_item_predicted_array.append(user_item_predicted.loc[test_df.User_Id[i]][test_df.Item_Id[i]])\n",
    "    \n",
    "    return np.array(user_item_predicted_array)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns rmse given predicted and observed rating arrays\n",
    "def calculate_rmse(predicted_rating,observed_rating):\n",
    "    rmse = np.sqrt((np.sum(np.square(predicted_rating-observed_rating)))/(len(observed_rating)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns mae given predicted and observed rating arrays\n",
    "def calculate_mae(predicted_rating,observed_rating):\n",
    "    mae = (np.sum(abs(predicted_rating-observed_rating)))/(len(observed_rating))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observed and Predicted Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print observed and predicted ratings, rmse and mae\n",
    "user_item_predicted_array = print_ratings(test_df,user_item_predicted)\n",
    "test_ratings_array = np.array(test_df.Rating)\n",
    "rmse = calculate_rmse(user_item_predicted_array,test_ratings_array)\n",
    "print(\"Root Mean Square Error for Test Data:\", rmse)\n",
    "mae = calculate_mae(user_item_predicted_array,test_ratings_array)\n",
    "print(\"Mean Absolute Error for Test Data:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns item coverage for dataset ie. percentage of items predicted from all items.\n",
    "def calculate_item_coverage(k,user_item_predicted):\n",
    "    items_recommended =[]\n",
    "    for i in range(0,user_item_predicted.shape[0]):\n",
    "        top_k_items=[]\n",
    "        target_user = user_item_predicted.index[i]\n",
    "        top_k_items=top_k_items_recommended(k,target_user,user_item_predicted)\n",
    "        items_recommended.extend(top_k_items)\n",
    "        \n",
    "    items_recommended = np.unique(np.array(items_recommended)).tolist()\n",
    "    items_coverage = len(items_recommended)/user_item_predicted.shape[1]\n",
    "    return items_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns top-k recommened items for any user\n",
    "def top_k_items_recommended(k,userid,user_item_predicted):\n",
    "    items_target = user_item_predicted.loc[userid].reset_index()\n",
    "    top_k_items = items_target.sort_values(userid, ascending=False)[:k].Item_Id.tolist()\n",
    "    return top_k_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catalog Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns catalog coverage for dataset ie. percentage of user-item pairs predicted from all possible user-item pairs\n",
    "def calculate_catalog_coverage(k,user_item_predicted):\n",
    "    total_user_item_pairs = user_item_predicted.shape[0]*user_item_predicted.shape[1]\n",
    "    #since recommending items to all the users\n",
    "    total_user_items_recommended = user_item_predicted.shape[0]*k\n",
    "    coverage_ratio = total_user_items_recommended/total_user_item_pairs\n",
    "    return coverage_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Item Coverage:\",calculate_item_coverage(5,user_item_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Catalog Coverage:\",calculate_catalog_coverage(5,user_item_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The time taken to run with these parameters:\", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
